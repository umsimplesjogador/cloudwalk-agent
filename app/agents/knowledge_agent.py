# from app.rag.vectorstore import VectorStore
# from app.llm.gemini_client import ask_gemini
# from typing import Dict

# class KnowledgeAgent:
#     def __init__(self):
#         self.vs = VectorStore()

#     def _filter_hits(self, hits, query):
#         query_lower = query.lower()
#         filtered = []

#         for h in hits:
#             meta = h["meta"]
#             source = meta.get("source", "")
#             section = meta.get("section", "")

#             # Mant√©m apenas conte√∫do Cloudwalk se for relevante
#             if "cloudwalk" in query_lower and "cloudwalk.io" not in source:
#                 continue

#             # Define peso por relev√¢ncia da se√ß√£o
#             weight = 1.0
#             if any(key in section.lower() for key in ["pillar", "mission", "about", "product", "ai"]):
#                 weight = 2.0

#             filtered.append({**h, "weight": weight})

#         # Ordena pelo peso
#         filtered = sorted(filtered, key=lambda x: x["weight"], reverse=True)

#         # üîπ AGRUPAR POR SE√á√ÉO
#         grouped = {}
#         for h in filtered:
#             sec = h["meta"].get("section", "general")
#             if sec not in grouped:
#                 grouped[sec] = []
#             grouped[sec].append(h)

#         # Se a query for sobre pilares, miss√£o ou valores, devolve **todos os blocos da se√ß√£o relevante**
#         if any(k in query_lower for k in ["pillar", "mission", "value"]):
#             relevant_sections = [sec for sec in grouped if any(k in sec.lower() for k in ["pillar", "mission", "value"])]
#             hits_final = []
#             for sec in relevant_sections:
#                 hits_final.extend(grouped[sec])
#             return hits_final

#         # Caso geral, pega top 6 hits
#         return filtered[:6]

#     def _format_context(self, hits):
#         """
#         Concatena todos os blocos mantendo a ordem original.
#         """
#         s = ""
#         for h in hits:
#             meta = h["meta"]
#             s += f"[Se√ß√£o: {meta.get('section')}] {h['text']} (Fonte: {meta.get('source')})\n\n"
#         return s
    

#     def answer(self, query: str) -> Dict:
#         # Recupera os trechos mais relevantes via FAISS
#         hits = self.vs.query(query, top_k=10)
#         hits = self._filter_hits(hits, query)
#         context = self._format_context(hits)

#         prompt = f"""Contexto sobre a Cloudwalk extra√≠do de v√°rias se√ß√µes do site:
# {context}

# Pergunta do usu√°rio:
# {query}

# Instru√ß√µes:
# - Baseie sua resposta **exclusivamente** no contexto acima.
# - Se o contexto contiver uma se√ß√£o espec√≠fica (ex: pillars, mission, products), use-a como fonte principal.
# - Responda em Portugu√™s, mas preserve nomes pr√≥prios e termos originais em ingl√™s (ex: Best Product).
# - N√£o invente informa√ß√µes que n√£o estejam no contexto.
# - Se a informa√ß√£o n√£o estiver dispon√≠vel, diga claramente que n√£o est√° no contexto e indique a se√ß√£o onde procurar.
# """

#         system_instruction = (
#             "Voc√™ √© um assistente especializado em informa√ß√µes institucionais da Cloudwalk, "
#             "incluindo miss√£o, pilares e produtos. Responda de forma fiel ao site oficial."
#         )

#         text = ask_gemini(prompt, system=system_instruction)
#         text = text.replace("\\n", "\n").strip()
#         sources = list({h['meta']['source'] for h in hits})

#         return {"answer": text, "sources": sources}
    









# from app.rag.vectorstore import VectorStore
# from typing import Dict

# class KnowledgeAgent:
#     def __init__(self):
#         self.vs = VectorStore()

#     def _filter_hits(self, hits, query):
#         """
#         Filtra e ordena os blocos por relev√¢ncia.
#         Para queries sobre pilares, miss√£o ou valores, retorna **todos os blocos da se√ß√£o**.
#         """
#         query_lower = query.lower()
#         filtered = []

#         for h in hits:
#             meta = h["meta"]
#             source = meta.get("source", "")
#             section = meta.get("section", "")

#             # Mant√©m apenas conte√∫do Cloudwalk se for relevante
#             if "cloudwalk" in query_lower and "cloudwalk.io" not in source:
#                 continue

#             # Define peso por relev√¢ncia da se√ß√£o
#             weight = 1.0
#             if any(key in section.lower() for key in ["pillar", "mission", "about", "product", "ai"]):
#                 weight = 2.0

#             filtered.append({**h, "weight": weight})

#         # Ordena pelo peso
#         filtered = sorted(filtered, key=lambda x: x["weight"], reverse=True)

#         # Agrupa por se√ß√£o
#         grouped = {}
#         for h in filtered:
#             sec = h["meta"].get("section", "general")
#             if sec not in grouped:
#                 grouped[sec] = []
#             grouped[sec].append(h)

#         # Para queries sobre pilares, miss√£o ou valores, devolve **todos os blocos da se√ß√£o relevante**
#         if any(k in query_lower for k in ["pillar", "pillars", "mission", "value", "values"]):
#             relevant_sections = [sec for sec in grouped if "pillar" in sec.lower()]
#             hits_final = []
#             for sec in relevant_sections:
#                 hits_final.extend(grouped[sec])
#             return hits_final

#         # Caso geral, retorna top 6
#         return filtered[:6]

#     def _format_context(self, hits):
#         """
#         Concatena todos os blocos mantendo a ordem original.
#         """
#         s = ""
#         for h in hits:
#             meta = h["meta"]
#             s += f"[Se√ß√£o: {meta.get('section')}] {h['text']} (Fonte: {meta.get('source')})\n\n"
#         return s

#     def answer(self, query: str) -> Dict:
#         # Recupera blocos do FAISS
#         hits = self.vs.query_for_hits(query, top_k=50)
#         hits = self._filter_hits(hits, query)

#         # Garante que h√° conte√∫do
#         if not hits:
#             return {"answer": "Os pilares da Cloudwalk n√£o est√£o no contexto fornecido. Consulte a se√ß√£o 'Pillars' no site oficial.", "sources": []}

#         # Monta prompt e chama Gemini
#         context = self._format_context(hits)
#         system_instruction = (
#             "Voc√™ √© um assistente especializado em informa√ß√µes institucionais da Cloudwalk, "
#             "incluindo miss√£o, pilares e produtos. Responda de forma fiel ao site oficial."
#         )

#         answer = self.vs.query_with_gemini(query, hits)
#         sources = list({h['meta'].get("source", "desconhecida") for h in hits})

#         return {"answer": answer, "sources": sources}





from app.rag.vectorstore import VectorStore
from typing import Dict

class KnowledgeAgent:
    def __init__(self):
        self.vs = VectorStore()

    def _filter_hits(self, hits, query):
        """
        Mant√©m hits relevantes por se√ß√£o e prioridade sem eliminar blocos √∫teis.
        """
        query_lower = query.lower()
        filtered = []

        for h in hits:
            meta = h["meta"]
            section = meta.get("section", "")
            source = meta.get("source", "")

            weight = 1.0
            if any(k in section.lower() for k in ["pillar", "pillars", "mission", "missions", "about", "product", "products", "ai"]):
                weight = 2.0

            filtered.append({**h, "weight": weight})

        filtered = sorted(filtered, key=lambda x: x["weight"], reverse=True)

        # Se a pergunta for sobre pilares, manter **todos os blocos da se√ß√£o**
        if any(k in query_lower for k in ["pillar", "pilares"]):
            return [h for h in filtered if "pillar" in h["meta"].get("section", "").lower()]

        return filtered[:6]

    def _format_context(self, hits):
        """
        Concatena todos os blocos mantendo estrutura.
        """
        s = ""
        for h in hits:
            meta = h["meta"]
            s += f"[Se√ß√£o: {meta.get('section')}] {h['text']} (Fonte: {meta.get('source')})\n\n"
        return s

    def answer(self, query: str) -> Dict:
        res = self.vs.query(query, top_k=10)
        hits = res["hits"]

        # Filtra e prepara o contexto
        hits = self._filter_hits(hits, query)
        context = self._format_context(hits)

        # Usa a resposta j√° gerada no VectorStore, se dispon√≠vel
        text = res["answer"].replace("\\n", "\n").strip()
        sources = list({h['meta']['source'] for h in hits})

        return {"answer": text, "sources": sources}
